1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?
В CUDA есть регистры и локальная память (самые быстрые), разделяемая память (быстрая, общая для блока) и глобальная память (самая медленная, но большая).

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?
Когда данные используются несколькими потоками одного блока или переиспользуются несколько раз, что позволяет сократить обращения к глобальной памяти.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?
Если доступ coalesced (соседние потоки читают соседние адреса), то производительность выше, а при non-coalesced доступе программа работает медленнее.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?
Потому что разные способы обращения к памяти создают разное количество транзакций, по-разному используют кэш и по-разному нагружают память.

5. Как размер блока потоков влияет на производительность CUDA-ядра?
Размер блока влияет на количество активных варпов и загрузку GPU: слишком маленькие блоки плохо используют ресурсы, а слишком большие могут ограничивать число активных блоков.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?
Варп — это группа из 32 потоков, выполняющихся одновременно. Если потоки варпа идут по разным веткам или обращаются к памяти неэффективно, производительность падает.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?
Нужно учитывать размер данных, архитектуру GPU, число регистров и shared memory, а также то, насколько хорошо блоки загружают GPU.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
Потому что в CUDA производительность чаще ограничена скоростью доступа к памяти, и правильная работа с памятью может дать большой прирост без изменения алгоритма.