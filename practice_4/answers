1. Чем отличаются типы памяти в CUDA и когда их использовать?
В CUDA есть глобальная, разделяемая, локальная и регистры. Глобальная память большая, но медленная — используется для хранения основных данных. Разделяемая память быстрая и общая для блока, подходит для промежуточных вычислений. Регистры и локальная память самые быстрые и используются для временных переменных потока.


2. Как использование разделяемой памяти влияет на производительность?
Разделяемая память намного быстрее глобальной, поэтому её использование уменьшает количество медленных обращений к глобальной памяти и ускоряет выполнение программы.


3. Что такое доступ к памяти и как обеспечить эффективный доступ?
Доступ к памяти — это чтение и запись данных. Эффективный доступ обеспечивается за счёт coalesced access, когда потоки читают соседние элементы памяти, и за счёт использования разделяемой памяти.


4. Какие сложности возникают при работе с большим объёмом данных на GPU?
Основные сложности — ограниченный объём видеопамяти, медленная передача данных между CPU и GPU и падение производительности из-за частых обращений к глобальной памяти.


5. Почему важно минимизировать доступ к глобальной памяти?
Потому что глобальная память имеет большую задержку, и частые обращения к ней сильно замедляют выполнение CUDA-программ.


6. Как использовать профилирование для анализа производительности CUDA-программ?
Для профилирования используют CUDA Events, nvprof или Nsight, чтобы измерять время выполнения ядер, находить узкие места и оптимизировать доступ к памяти и загрузку GPU.

